{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723997c3",
   "metadata": {},
   "source": [
    "# Meta-learning for Domain Adaptation in Sentiment Analysis\n",
    "\n",
    "This repository contains the code for comparing the following three approaches on sentiment analysis with domain shift: \n",
    "* Hard-shared multitask learning\n",
    "* [Prototypical network](https://arxiv.org/abs/1703.05175)\n",
    "* [Model-agnostic meta-learning (MAML)](https://arxiv.org/abs/1703.03400)\n",
    "We used the [Fudan review dataset](https://github.com/FrankWork/fudan_mtl_reviews) with sentiment labels on 16 domains.\n",
    "All models use an architecture based on [BERT](https://arxiv.org/abs/1810.04805) with a feedworward head.\n",
    "\n",
    "## Usage\n",
    "The used packages can be installed with\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "The general command for running a model is as follows\n",
    "```\n",
    "python <MAIN_SCRIPT> --trainer=<TRAINER_NAME> --config=configs.<CONFIG_FILE> --<MODE>\n",
    "```\n",
    "Where the MAIN_SCRIPT can be one of the following two:\n",
    "* main.py to run the model once\n",
    "* main_loop.py to run the model 3 times with different random seeds (otherwise they are the same)\n",
    "<!-- end of the list -->\n",
    "The TRAINER_NAME can be either:\n",
    "* multitask\n",
    "* prototypical\n",
    "* maml\n",
    "<!-- end of the list -->\n",
    "The CONFIG_FILE is a file that contains all the hyperparameters for training, see the examples for training in the configs folder and see detailed usage and the full list of config arguments [here](https://github.com/AmanDaVinci/meta-infomax/blob/master/configs/Readme.md).\\\n",
    "\\\n",
    "MODE flag can be\n",
    "* train\n",
    "* test\n",
    "<!-- end of the list -->\n",
    "Both flags can be used at the same time.\\\n",
    "\\\n",
    "An example of the usage for training maml with 3 different seeds on the dvd test dataset would be:\n",
    "```\n",
    "python main_loop.py --trainer=maml --config=configs.maml_config_dvd --train\n",
    "```\n",
    "For more examples on the usage and analysis of the models, see the notebooks folder.\n",
    "## File structure\n",
    "\n",
    "    .\n",
    "    ├── configs                         # config files with hyperparameters\n",
    "        |──base_config.py               # contains default parameters\n",
    "        |──..._config.py                # run specific parameters (extend and overwrite base)\n",
    "    ├── meta_infomax                    # contains most parts of the implementation of the project\n",
    "        ├──datasets                     # scripts for processing and representing the data\n",
    "        ├──losses                       # contains the specific loss function for ProtoNet\n",
    "        ├──models                       # contains the files for the shared model architecture (BERT, ffn head etc.)\n",
    "        ├──trainers                     # The spedific trainer classes for the different approaches\n",
    "            ├──evaluation_trainer.py    # Class for evaluating trained models, currently compatible with ProtoNet\n",
    "            ├──fomaml_trainer.py        # Class for first-order MAML approximation\n",
    "            ├──maml_trainer.py          # Class for original MAML (not used for the project)\n",
    "            ├──multitask_trainer.py     # Class for hard-shared multitask model\n",
    "            ├──PMIScorer.py             # Class for calculating PMI scores and sort domains based on that\n",
    "            ├──protonet_trainer.py      # Class for Prototypical Network implementation\n",
    "            |──super_trainer.py         # Superclass of the above classes\n",
    "    ├── notebooks                       # contains usage and analyses example notebooks\n",
    "    ├── checkpoints*                    # Stored models from training\n",
    "        |──...                          # model specific folders, name extracted from config\n",
    "    ├── data/mtl_dataset                # Processed data files per domain and split\n",
    "    ├── results*\n",
    "        |──.../logs                     # model specific folders, name extracted from config\n",
    "                |──....0                # tensorboard logs for the model\n",
    "                |──logs.log             # logging output\n",
    "    ├── .gitignore                  \n",
    "    ├── LICENSE\n",
    "    ├── README.md\n",
    "    ├── main.py                         # Run model once\n",
    "    ├── main_loop.py                    # Run model 3 times with different seeds\n",
    "    └── requirements.txt                # Install for used packages\n",
    "\n",
    "    Note: folders with * and their subfolders are created automatically during run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shadi-python3-kernel",
   "language": "python",
   "name": "shadi-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
