{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created small test dataset: ../data/arabic/small/res1.task.test\n",
      "Created small test dataset: ../data/arabic/small/htl.task.test\n",
      "Created small training dataset: ../data/arabic/small/astd.task.train\n",
      "Created small training dataset: ../data/arabic/small/mov.task.train\n",
      "Created small training dataset: ../data/arabic/small/prod.task.train\n",
      "Created small test dataset: ../data/arabic/small/bard.task.test\n",
      "Created small training dataset: ../data/arabic/small/res2.task.train\n",
      "Created small training dataset: ../data/arabic/small/tsac.task.train\n",
      "Created small test dataset: ../data/arabic/small/tead.task.test\n",
      "Created small test dataset: ../data/arabic/small/hard.task.test\n",
      "Created small test dataset: ../data/arabic/small/res2.task.test\n",
      "Created small test dataset: ../data/arabic/small/labr.task.test\n",
      "Created small training dataset: ../data/arabic/small/htl.task.train\n",
      "Created small test dataset: ../data/arabic/small/tsac.task.test\n",
      "Created small training dataset: ../data/arabic/small/att.task.train\n",
      "Created small training dataset: ../data/arabic/small/res1.task.train\n",
      "Created small test dataset: ../data/arabic/small/mov.task.test\n",
      "Created small test dataset: ../data/arabic/small/prod.task.test\n",
      "Created small test dataset: ../data/arabic/small/att.task.test\n",
      "Created small test dataset: ../data/arabic/small/astd.task.test\n",
      "Created small training dataset: ../data/arabic/small/labr.task.train\n",
      "Created small training dataset: ../data/arabic/small/bard.task.train\n",
      "Created small training dataset: ../data/arabic/small/hard.task.train\n",
      "Created small test dataset: ../data/arabic/small/arsas.task.test\n",
      "Created small training dataset: ../data/arabic/small/tead.task.train\n",
      "Created small training dataset: ../data/arabic/small/arsas.task.train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# data_dir = \"../data/amazon-utf8/data-mbert-utf8/mtl-dataset\"  # Directory containing the original datasets\n",
    "# small_data_dir = \"../data/small-data\"  # Directory for smaller datasets\n",
    "\n",
    "data_dir = \"../data/arabic/all\"\n",
    "small_data_dir = \"../data/arabic/small\"\n",
    "\n",
    "train_suffix = \".task.train\"\n",
    "test_suffix = \".task.test\"\n",
    "\n",
    "train_sample_size = 100\n",
    "test_sample_size = 20\n",
    "\n",
    "# Create the small data directory if it doesn't exist\n",
    "os.makedirs(small_data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if not os.path.isfile(filepath):  # Skip if not a file (e.g., subdirectory)\n",
    "        continue\n",
    "\n",
    "    if filename.endswith(train_suffix):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep='\\t', header=None, encoding='utf-8')  # Read TSV, no header\n",
    "            small_df = df.sample(n=train_sample_size, random_state=42)  # Randomly sample 100 rows\n",
    "            small_filepath = os.path.join(small_data_dir, filename)\n",
    "            small_df.to_csv(small_filepath, sep='\\t', header=False, index=False)  # Save as TSV, no header/index\n",
    "            print(f\"Created small training dataset: {small_filepath}\")\n",
    "        except pd.errors.EmptyDataError: #handle empty files\n",
    "            print(f\"Skipping empty file: {filepath}\")\n",
    "        except Exception as e:\n",
    "             print(f\"An error occurred processing {filename}: {e}\")\n",
    "\n",
    "    elif filename.endswith(test_suffix):\n",
    "         try:\n",
    "            df = pd.read_csv(filepath, sep='\\t', header=None)\n",
    "            small_df = df.sample(n=test_sample_size, random_state=42)\n",
    "            small_filepath = os.path.join(small_data_dir, filename)\n",
    "            small_df.to_csv(small_filepath, sep='\\t', header=False, index=False)\n",
    "            print(f\"Created small test dataset: {small_filepath}\")\n",
    "         except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {filepath}\")\n",
    "         except Exception as e:\n",
    "             print(f\"An error occurred processing {filename}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv10_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
