{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split tead into training (../data/arabic/all/tead.task.train) and test (../data/arabic/all/tead.task.test) sets.\n",
      "Split tsac into training (../data/arabic/all/tsac.task.train) and test (../data/arabic/all/tsac.task.test) sets.\n",
      "Split att into training (../data/arabic/all/att.task.train) and test (../data/arabic/all/att.task.test) sets.\n",
      "Split labr into training (../data/arabic/all/labr.task.train) and test (../data/arabic/all/labr.task.test) sets.\n",
      "Split res1 into training (../data/arabic/all/res1.task.train) and test (../data/arabic/all/res1.task.test) sets.\n",
      "Split prod into training (../data/arabic/all/prod.task.train) and test (../data/arabic/all/prod.task.test) sets.\n",
      "Split hard into training (../data/arabic/all/hard.task.train) and test (../data/arabic/all/hard.task.test) sets.\n",
      "Split astd into training (../data/arabic/all/astd.task.train) and test (../data/arabic/all/astd.task.test) sets.\n",
      "Split arsas into training (../data/arabic/all/arsas.task.train) and test (../data/arabic/all/arsas.task.test) sets.\n",
      "Split mov into training (../data/arabic/all/mov.task.train) and test (../data/arabic/all/mov.task.test) sets.\n",
      "Split htl into training (../data/arabic/all/htl.task.train) and test (../data/arabic/all/htl.task.test) sets.\n",
      "Split res2 into training (../data/arabic/all/res2.task.train) and test (../data/arabic/all/res2.task.test) sets.\n",
      "Split bard into training (../data/arabic/all/bard.task.train) and test (../data/arabic/all/bard.task.test) sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def split_tsv_train_test(data_dir, train_dir, test_dir, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits TSV files in a directory into training and test sets, maintaining class proportions.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to the directory containing the original TSV files.\n",
    "        train_dir: Path to the directory to store the training TSV files.\n",
    "        test_dir: Path to the directory to store the test TSV files.\n",
    "        train_ratio: The proportion of data to use for training (default: 0.8).\n",
    "    \"\"\"\n",
    "    os.makedirs(train_dir, exist_ok=True)  # Create directories if they don't exist\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if os.path.isfile(os.path.join(data_dir, filename)): #only files, not subdirectories\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, sep='\\t', header=None, names=['sentiment','text'])\n",
    "\n",
    "                # Separate positive and negative examples:\n",
    "                df_pos = df[df['sentiment'] == 1]\n",
    "                df_neg = df[df['sentiment'] == 0]\n",
    "\n",
    "                # Calculate the number of samples for each set:\n",
    "                train_pos_size = int(len(df_pos) * train_ratio)\n",
    "                test_pos_size = len(df_pos) - train_pos_size\n",
    "                train_neg_size = int(len(df_neg) * train_ratio)\n",
    "                test_neg_size = len(df_neg) - train_neg_size\n",
    "\n",
    "\n",
    "                # Sample training and test sets while preserving class distribution:\n",
    "                train_pos = df_pos.sample(n=train_pos_size)\n",
    "                test_pos = df_pos.drop(train_pos.index)\n",
    "                train_neg = df_neg.sample(n=train_neg_size)\n",
    "                test_neg = df_neg.drop(train_neg.index)\n",
    "\n",
    "\n",
    "                # Concatenate positive and negative examples for training and test:\n",
    "                df_train = pd.concat([train_pos, train_neg])\n",
    "                df_test = pd.concat([test_pos, test_neg])\n",
    "\n",
    "                # Save the training and test sets to TSV files:\n",
    "                train_filepath = os.path.join(train_dir, filename + \".task.train\") #add the .train suffix\n",
    "                test_filepath = os.path.join(test_dir, filename + \".task.test\") #add the .test suffix\n",
    "                df_train.to_csv(train_filepath, sep='\\t', header=False, index=False)\n",
    "                df_test.to_csv(test_filepath, sep='\\t', header=False, index=False)\n",
    "                print(f\"Split {filename} into training ({train_filepath}) and test ({test_filepath}) sets.\")\n",
    "\n",
    "\n",
    "            except pd.errors.EmptyDataError:  # Handle empty files\n",
    "                print(f\"Skipping empty file: {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "data_dir = \"/home/shadi2/phd/code/anbera-univ/large-arabic-sentiment-analysis-resouces/preprocess_urls_hashtags\"\n",
    "train_dir = \"../data/arabic/all\"\n",
    "test_dir = \"../data/arabic/all\"\n",
    "\n",
    "split_tsv_train_test(data_dir, train_dir, test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv10_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
